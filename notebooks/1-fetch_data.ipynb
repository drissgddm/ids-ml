{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to download data from https://www.unb.ca/cic/datasets/ids-2018.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But let's see first what's in the bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-10-10 13:52:09    0 Bytes Original Network Traffic and Log data/\r\n",
      "2018-10-10 13:52:23    0 Bytes Original Network Traffic and Log data/Friday-02-03-2018/\r\n",
      "2018-10-10 14:00:39  225.8 MiB Original Network Traffic and Log data/Friday-02-03-2018/logs.zip\r\n",
      "2018-10-10 14:00:51   41.7 GiB Original Network Traffic and Log data/Friday-02-03-2018/pcap.zip\r\n",
      "2018-10-10 13:52:34    0 Bytes Original Network Traffic and Log data/Friday-16-02-2018/\r\n",
      "2018-10-10 14:45:49  148.1 MiB Original Network Traffic and Log data/Friday-16-02-2018/logs.zip\r\n",
      "2018-10-10 14:46:01   35.9 GiB Original Network Traffic and Log data/Friday-16-02-2018/pcap.zip\r\n",
      "2018-10-10 13:52:41    0 Bytes Original Network Traffic and Log data/Friday-23-02-2018/\r\n",
      "2018-10-10 14:46:10  199.8 MiB Original Network Traffic and Log data/Friday-23-02-2018/logs.zip\r\n",
      "2018-10-10 14:46:31   55.0 GiB Original Network Traffic and Log data/Friday-23-02-2018/pcap.zip\r\n",
      "2018-10-10 13:52:47    0 Bytes Original Network Traffic and Log data/Thursday-01-03-2018/\r\n",
      "2018-10-10 15:41:13  217.1 MiB Original Network Traffic and Log data/Thursday-01-03-2018/logs.zip\r\n",
      "2018-10-10 15:41:45   48.8 GiB Original Network Traffic and Log data/Thursday-01-03-2018/pcap.zip\r\n",
      "2018-10-10 13:52:54    0 Bytes Original Network Traffic and Log data/Thursday-15-02-2018/\r\n",
      "2018-10-10 15:41:28  142.6 MiB Original Network Traffic and Log data/Thursday-15-02-2018/logs.zip\r\n",
      "2018-10-10 15:41:55   38.4 GiB Original Network Traffic and Log data/Thursday-15-02-2018/pcap.zip\r\n",
      "2018-10-10 13:53:01    0 Bytes Original Network Traffic and Log data/Thursday-22-02-2018/\r\n",
      "2018-10-10 15:41:42  195.3 MiB Original Network Traffic and Log data/Thursday-22-02-2018/logs.zip\r\n",
      "2018-10-10 15:42:27   46.8 GiB Original Network Traffic and Log data/Thursday-22-02-2018/pcap.zip\r\n",
      "2018-10-10 13:53:07    0 Bytes Original Network Traffic and Log data/Tuesday-20-02-2018/\r\n",
      "2018-10-10 16:39:45  178.9 MiB Original Network Traffic and Log data/Tuesday-20-02-2018/logs.zip\r\n",
      "2018-10-10 16:40:40   41.3 GiB Original Network Traffic and Log data/Tuesday-20-02-2018/pcap.rar\r\n",
      "2018-10-10 13:53:14    0 Bytes Original Network Traffic and Log data/Wednesday-14-02-2018/\r\n",
      "2018-10-10 18:44:20  133.7 MiB Original Network Traffic and Log data/Wednesday-14-02-2018/logs.zip\r\n",
      "2018-10-11 14:22:03   37.2 GiB Original Network Traffic and Log data/Wednesday-14-02-2018/pcap.zip\r\n",
      "2018-10-10 13:53:21    0 Bytes Original Network Traffic and Log data/Wednesday-21-02-2018/\r\n",
      "2018-10-10 18:44:34  185.6 MiB Original Network Traffic and Log data/Wednesday-21-02-2018/logs.zip\r\n",
      "2018-10-11 15:35:15   49.8 GiB Original Network Traffic and Log data/Wednesday-21-02-2018/pcap.zip\r\n",
      "2018-10-10 13:53:28    0 Bytes Original Network Traffic and Log data/Wednesday-28-02-2018/\r\n",
      "2018-10-10 18:44:47  216.1 MiB Original Network Traffic and Log data/Wednesday-28-02-2018/logs.zip\r\n",
      "2018-10-11 16:21:03   49.6 GiB Original Network Traffic and Log data/Wednesday-28-02-2018/pcap.zip\r\n",
      "2018-10-11 18:02:25    0 Bytes Processed Traffic Data for ML Algorithms/\r\n",
      "2018-10-11 18:02:49  336.0 MiB Processed Traffic Data for ML Algorithms/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv\r\n",
      "2018-10-11 18:03:10  318.3 MiB Processed Traffic Data for ML Algorithms/Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\r\n",
      "2018-10-11 18:03:33  365.1 MiB Processed Traffic Data for ML Algorithms/Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\r\n",
      "2018-10-11 18:03:59    3.8 GiB Processed Traffic Data for ML Algorithms/Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv\r\n",
      "2018-10-11 18:08:38  102.8 MiB Processed Traffic Data for ML Algorithms/Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv\r\n",
      "2018-10-11 18:08:48  358.5 MiB Processed Traffic Data for ML Algorithms/Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv\r\n",
      "2018-10-11 18:09:20  364.9 MiB Processed Traffic Data for ML Algorithms/Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv\r\n",
      "2018-10-11 18:09:44  341.6 MiB Processed Traffic Data for ML Algorithms/Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv\r\n",
      "2018-10-11 18:10:12  313.7 MiB Processed Traffic Data for ML Algorithms/Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv\r\n",
      "2018-10-11 18:10:33  199.6 MiB Processed Traffic Data for ML Algorithms/Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\r\n",
      "\r\n",
      "Total Objects: 42\r\n",
      "   Total Size: 452.8 GiB\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls --no-sign-request \"s3://cse-cic-ids2018\" --recursive --human-readable --summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now download only the csv files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --no-sign-request \"s3://cse-cic-ids2018/Processed Traffic Data for ML Algorithms/\" data/ --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Friday-02-03-2018_TrafficForML_CICFlowMeter.csv\r\n",
      "Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\r\n",
      "Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\r\n",
      "Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv\r\n",
      "Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv\r\n",
      "Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv\r\n",
      "Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv\r\n",
      "Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv\r\n",
      "Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv\r\n",
      "Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = [\n",
    "    \"Friday-02-03-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "    \"Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "    \"Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "    \"Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "    \"Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "    \"Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "    \"Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "    \"Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "    \"Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "    \"Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "]\n",
    "\n",
    "dates_by_datasets = {\n",
    "    \"Friday-02-03-2018_TrafficForML_CICFlowMeter.csv\": \"02-03-2018\",\n",
    "    \"Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\": \"16-02-2018\",\n",
    "    \"Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\": \"23-02-2018\",\n",
    "    \"Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv\": \"23-02-2018\",\n",
    "    \"Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv\": \"01-03-2018\",\n",
    "    \"Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv\": \"15-02-2018\",\n",
    "    \"Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv\": \"22-02-2018\",\n",
    "    \"Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv\": \"14-02-2018\",\n",
    "    \"Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv\": \"21-02-2018\",\n",
    "    \"Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\": \"28-02-2018\",\n",
    "}\n",
    "\n",
    "train_test_validation_datasets_split = {\n",
    "    \"train\": [\n",
    "        \"Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "        \"Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "    ],\n",
    "    \"test\": [\n",
    "        \"Friday-02-03-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "        \"Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "        \"Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "        \"Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "        \"Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv\"\n",
    "    ],\n",
    "    \"validate\": [\n",
    "        \"Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "        \"Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "        \"Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and concat data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({})\n",
    "dataset = \"validate\"\n",
    "\n",
    "for csv in train_test_validation_datasets_split[dataset]:\n",
    "\n",
    "    df = pd.concat([df, pd.read_csv(\"data/{}\".format(csv))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3145725, 80)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dst Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Tot Fwd Pkts</th>\n",
       "      <th>Tot Bwd Pkts</th>\n",
       "      <th>TotLen Fwd Pkts</th>\n",
       "      <th>TotLen Bwd Pkts</th>\n",
       "      <th>Fwd Pkt Len Max</th>\n",
       "      <th>Fwd Pkt Len Min</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd Seg Size Min</th>\n",
       "      <th>Active Mean</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15/02/2018 08:25:18</td>\n",
       "      <td>112641158</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56320579.0</td>\n",
       "      <td>7.042784e+02</td>\n",
       "      <td>56321077</td>\n",
       "      <td>56320081</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>15/02/2018 08:29:05</td>\n",
       "      <td>37366762</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>2168</td>\n",
       "      <td>2993</td>\n",
       "      <td>712</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>1024353.0</td>\n",
       "      <td>649038.754495</td>\n",
       "      <td>1601183</td>\n",
       "      <td>321569</td>\n",
       "      <td>11431221.0</td>\n",
       "      <td>3.644991e+06</td>\n",
       "      <td>15617415</td>\n",
       "      <td>8960247</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47514</td>\n",
       "      <td>6</td>\n",
       "      <td>15/02/2018 08:29:42</td>\n",
       "      <td>543</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15/02/2018 08:28:07</td>\n",
       "      <td>112640703</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56320351.5</td>\n",
       "      <td>3.669884e+02</td>\n",
       "      <td>56320611</td>\n",
       "      <td>56320092</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15/02/2018 08:30:56</td>\n",
       "      <td>112640874</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56320437.0</td>\n",
       "      <td>7.198347e+02</td>\n",
       "      <td>56320946</td>\n",
       "      <td>56319928</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dst Port  Protocol            Timestamp  Flow Duration  Tot Fwd Pkts  \\\n",
       "0         0         0  15/02/2018 08:25:18      112641158             3   \n",
       "1        22         6  15/02/2018 08:29:05       37366762            14   \n",
       "2     47514         6  15/02/2018 08:29:42            543             2   \n",
       "3         0         0  15/02/2018 08:28:07      112640703             3   \n",
       "4         0         0  15/02/2018 08:30:56      112640874             3   \n",
       "\n",
       "   Tot Bwd Pkts  TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  \\\n",
       "0             0                0                0                0   \n",
       "1            12             2168             2993              712   \n",
       "2             0               64                0               64   \n",
       "3             0                0                0                0   \n",
       "4             0                0                0                0   \n",
       "\n",
       "   Fwd Pkt Len Min  ...  Fwd Seg Size Min  Active Mean     Active Std  \\\n",
       "0                0  ...                 0          0.0       0.000000   \n",
       "1                0  ...                32    1024353.0  649038.754495   \n",
       "2                0  ...                32          0.0       0.000000   \n",
       "3                0  ...                 0          0.0       0.000000   \n",
       "4                0  ...                 0          0.0       0.000000   \n",
       "\n",
       "   Active Max  Active Min   Idle Mean      Idle Std  Idle Max  Idle Min  \\\n",
       "0           0           0  56320579.0  7.042784e+02  56321077  56320081   \n",
       "1     1601183      321569  11431221.0  3.644991e+06  15617415   8960247   \n",
       "2           0           0         0.0  0.000000e+00         0         0   \n",
       "3           0           0  56320351.5  3.669884e+02  56320611  56320092   \n",
       "4           0           0  56320437.0  7.198347e+02  56320946  56319928   \n",
       "\n",
       "    Label  \n",
       "0  Benign  \n",
       "1  Benign  \n",
       "2  Benign  \n",
       "3  Benign  \n",
       "4  Benign  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dst Port', 'Protocol', 'Timestamp', 'Flow Duration', 'Tot Fwd Pkts',\n",
       "       'Tot Bwd Pkts', 'TotLen Fwd Pkts', 'TotLen Bwd Pkts', 'Fwd Pkt Len Max',\n",
       "       'Fwd Pkt Len Min', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std',\n",
       "       'Bwd Pkt Len Max', 'Bwd Pkt Len Min', 'Bwd Pkt Len Mean',\n",
       "       'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean',\n",
       "       'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Tot',\n",
       "       'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min',\n",
       "       'Bwd IAT Tot', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max',\n",
       "       'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags',\n",
       "       'Bwd URG Flags', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s',\n",
       "       'Bwd Pkts/s', 'Pkt Len Min', 'Pkt Len Max', 'Pkt Len Mean',\n",
       "       'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt',\n",
       "       'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt',\n",
       "       'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Pkt Size Avg',\n",
       "       'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg',\n",
       "       'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg',\n",
       "       'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts',\n",
       "       'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts',\n",
       "       'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts',\n",
       "       'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max',\n",
       "       'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min', 'Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export them in split and compressed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/driss/miniconda3/envs/ids-ml/lib/python3.9/zipfile.py:1505: UserWarning: Duplicate name: 'out.csv'\n",
      "  return self._open_to_write(zinfo, force_zip64=force_zip64)\n"
     ]
    }
   ],
   "source": [
    "compression_opts = dict(method='zip', archive_name='out.csv') \n",
    "df.to_csv('{}.zip'.format(dataset), index=False, compression=compression_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-fetch_data.ipynb  data  test.zip  train.zip  validate.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
